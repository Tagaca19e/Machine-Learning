{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuralNetwork2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRUmuKXZcqc1",
        "outputId": "5c5f5cbf-cc0f-482c-f285-db37c25c080c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 10.3182 - mae: 10.3182\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.2682 - mae: 10.2682\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.2182 - mae: 10.2182\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.1682 - mae: 10.1682\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.1182 - mae: 10.1182\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.0682 - mae: 10.0682\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.0182 - mae: 10.0182\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.9682 - mae: 9.9682\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9182 - mae: 9.9182\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 9.8682 - mae: 9.8682\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f989b87da90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "np1 = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0])\n",
        "np2 = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0])\n",
        "\n",
        "\n",
        "#model is only 32 bits\n",
        "\n",
        "X = tf.constant(np1, shape=(7,1),dtype=tf.float32)\n",
        "Y = tf.constant(np2, shape=(7,1) ,dtype=tf.float32)\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([ \n",
        "        tf.keras.layers.Dense(1)\n",
        "        # tf.keras.layers.Dense(1)\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "#MAE = mean absolute error\n",
        "\n",
        "#improving the model\n",
        "#changing the layers\n",
        "#adding activation function\n",
        "\n",
        "#compiling a model\n",
        "#fitting the model, and adjusting the epochs\n",
        "\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = ['mae'])\n",
        "\n",
        "\n",
        "#metrics = human readable data so we can evaluate the model\n",
        "#optimizer =how your model should update its internal patterns to better its precitions. \n",
        "\n",
        "\n",
        "model.fit(X, Y, epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "np1 = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0])\n",
        "np2 = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0])\n",
        "\n",
        "\n",
        "#model is only 32 bits\n",
        "\n",
        "X = tf.constant(np1, shape=(7,1),dtype=tf.float32)\n",
        "Y = tf.constant(np2, shape=(7,1) ,dtype=tf.float32)\n",
        "\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        # tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "        # tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(100, activation=None),                          \n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.Adam(lr=0.1),\n",
        "              metrics=['mae'])\n",
        "\n",
        "model.fit(X, Y, epochs=100)\n",
        "\n",
        "model.predict([17.0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMA-P3xdfZ5B",
        "outputId": "13335666-78e9-4e51-a8ba-174254ef6aa8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 10.9826 - mae: 10.9826\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.7216 - mae: 11.7216\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1176 - mae: 7.1176\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.7980 - mae: 6.7980\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5548 - mae: 4.5548\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1462 - mae: 6.1462\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3464 - mae: 4.3464\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9819 - mae: 0.9819\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0173 - mae: 2.0173\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0898 - mae: 2.0898\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2188 - mae: 1.2188\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9165 - mae: 1.9165\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3095 - mae: 2.3095\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5576 - mae: 1.5576\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0189 - mae: 2.0189\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3536 - mae: 2.3536\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8646 - mae: 0.8646\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9325 - mae: 1.9325\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8679 - mae: 2.8679\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5059 - mae: 2.5059\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0720 - mae: 1.0720\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6463 - mae: 1.6463\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3322 - mae: 2.3322\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2975 - mae: 1.2975\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5056 - mae: 1.5056\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9970 - mae: 1.9970\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2882 - mae: 1.2882\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2114 - mae: 1.2114\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5905 - mae: 1.5905\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5165 - mae: 0.5165\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6592 - mae: 1.6592\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3191 - mae: 2.3191\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7866 - mae: 1.7866\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4210 - mae: 0.4210\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9406 - mae: 1.9406\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6855 - mae: 2.6855\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0547 - mae: 2.0547\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3951 - mae: 0.3951\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1271 - mae: 2.1271\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1474 - mae: 3.1474\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3493 - mae: 3.3493\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7521 - mae: 2.7521\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4236 - mae: 1.4236\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7591 - mae: 0.7591\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7194 - mae: 1.7194\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6477 - mae: 1.6477\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8993 - mae: 1.8993\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7196 - mae: 1.7196\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4474 - mae: 0.4474\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9657 - mae: 1.9657\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5739 - mae: 2.5739\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8350 - mae: 1.8350\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8747 - mae: 1.8747\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1523 - mae: 2.1523\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6290 - mae: 1.6290\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5140 - mae: 0.5140\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7390 - mae: 1.7390\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5624 - mae: 2.5624\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2184 - mae: 2.2184\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9955 - mae: 0.9955\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5917 - mae: 1.5917\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4608 - mae: 1.4608\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0891 - mae: 1.0891\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1245 - mae: 2.1245\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4929 - mae: 2.4929\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3528 - mae: 1.3528\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0422 - mae: 1.0422\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6325 - mae: 1.6325\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3217 - mae: 1.3217\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2239 - mae: 1.2239\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 1.5567 - mae: 1.5567\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1591 - mae: 1.1591\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6069 - mae: 0.6069\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0748 - mae: 1.0748\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7093 - mae: 0.7093\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4606 - mae: 0.4606\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5826 - mae: 0.5826\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9431 - mae: 0.9431\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6728 - mae: 0.6728\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7642 - mae: 0.7642\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7259 - mae: 0.7259\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8767 - mae: 0.8767\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1264 - mae: 1.1264\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4522 - mae: 0.4522\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3397 - mae: 1.3397\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7040 - mae: 1.7040\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9188 - mae: 0.9188\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8596 - mae: 0.8596\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2283 - mae: 1.2283\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7663 - mae: 0.7663\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6957 - mae: 0.6957\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9741 - mae: 0.9741\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3370 - mae: 0.3370\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9592 - mae: 0.9592\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1544 - mae: 1.1544\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5533 - mae: 0.5533\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1785 - mae: 1.1785\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5462 - mae: 1.5462\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8417 - mae: 0.8417\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7361 - mae: 0.7361\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.370169]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = tf.range(-100, 100, 4)\n",
        "\n",
        "Y1 = tf.add(X1, 10)\n",
        "\n",
        "Y1, X1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UFDJ7shl8e6",
        "outputId": "663afa22-9de4-4fb3-ca25-ee871599d9ab"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>,\n",
              " <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "          76,   80,   84,   88,   92,   96], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.scatter(X1, Y1)\n",
        "\n",
        "X1 = tf.reshape(X1, [50,1])\n",
        "Y1 = tf.reshape(Y1, [50,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "twKc3rFYsgVr",
        "outputId": "3d5b4d43-d4cc-459f-d741-efa75c52d9a9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the data to train and test sets\n",
        "\n",
        "XTrain = X1[:40]\n",
        "XTest = X1[40:]\n",
        "\n",
        "YTrain = Y1[:40]\n",
        "YTest = Y1[40:]\n",
        "           \n",
        "X1, XTrain, XTest\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M9ru83SuvRH",
        "outputId": "e2e0c573-08f6-4d99-f2f0-28cda54e4124"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(50, 1), dtype=int32, numpy=\n",
              " array([[-100],\n",
              "        [ -96],\n",
              "        [ -92],\n",
              "        [ -88],\n",
              "        [ -84],\n",
              "        [ -80],\n",
              "        [ -76],\n",
              "        [ -72],\n",
              "        [ -68],\n",
              "        [ -64],\n",
              "        [ -60],\n",
              "        [ -56],\n",
              "        [ -52],\n",
              "        [ -48],\n",
              "        [ -44],\n",
              "        [ -40],\n",
              "        [ -36],\n",
              "        [ -32],\n",
              "        [ -28],\n",
              "        [ -24],\n",
              "        [ -20],\n",
              "        [ -16],\n",
              "        [ -12],\n",
              "        [  -8],\n",
              "        [  -4],\n",
              "        [   0],\n",
              "        [   4],\n",
              "        [   8],\n",
              "        [  12],\n",
              "        [  16],\n",
              "        [  20],\n",
              "        [  24],\n",
              "        [  28],\n",
              "        [  32],\n",
              "        [  36],\n",
              "        [  40],\n",
              "        [  44],\n",
              "        [  48],\n",
              "        [  52],\n",
              "        [  56],\n",
              "        [  60],\n",
              "        [  64],\n",
              "        [  68],\n",
              "        [  72],\n",
              "        [  76],\n",
              "        [  80],\n",
              "        [  84],\n",
              "        [  88],\n",
              "        [  92],\n",
              "        [  96]], dtype=int32)>, <tf.Tensor: shape=(40, 1), dtype=int32, numpy=\n",
              " array([[-100],\n",
              "        [ -96],\n",
              "        [ -92],\n",
              "        [ -88],\n",
              "        [ -84],\n",
              "        [ -80],\n",
              "        [ -76],\n",
              "        [ -72],\n",
              "        [ -68],\n",
              "        [ -64],\n",
              "        [ -60],\n",
              "        [ -56],\n",
              "        [ -52],\n",
              "        [ -48],\n",
              "        [ -44],\n",
              "        [ -40],\n",
              "        [ -36],\n",
              "        [ -32],\n",
              "        [ -28],\n",
              "        [ -24],\n",
              "        [ -20],\n",
              "        [ -16],\n",
              "        [ -12],\n",
              "        [  -8],\n",
              "        [  -4],\n",
              "        [   0],\n",
              "        [   4],\n",
              "        [   8],\n",
              "        [  12],\n",
              "        [  16],\n",
              "        [  20],\n",
              "        [  24],\n",
              "        [  28],\n",
              "        [  32],\n",
              "        [  36],\n",
              "        [  40],\n",
              "        [  44],\n",
              "        [  48],\n",
              "        [  52],\n",
              "        [  56]], dtype=int32)>, <tf.Tensor: shape=(10, 1), dtype=int32, numpy=\n",
              " array([[60],\n",
              "        [64],\n",
              "        [68],\n",
              "        [72],\n",
              "        [76],\n",
              "        [80],\n",
              "        [84],\n",
              "        [88],\n",
              "        [92],\n",
              "        [96]], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XTrain = tf.cast(Xtrain, shape=())\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "          tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model2.compile(loss=tf.keras.losses.mae,\n",
        "               optimizer = tf.keras.optimizers.Adam(lr=0.01),\n",
        "               metrics = ['mae'])\n",
        "\n",
        "model2.fit(XTrain, YTrain, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oX8Q3OIn156z",
        "outputId": "5fc1f5bf-e994-42c8-9cca-733fec16b994"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 5ms/step - loss: 58.6047 - mae: 58.6047\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 57.7546 - mae: 57.7546\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 56.8765 - mae: 56.8765\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 56.0396 - mae: 56.0396\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 55.1591 - mae: 55.1591\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 54.3330 - mae: 54.3330\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 53.4547 - mae: 53.4547\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 52.5841 - mae: 52.5841\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 51.7512 - mae: 51.7512\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 50.8850 - mae: 50.8850\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 50.0313 - mae: 50.0313\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 49.1884 - mae: 49.1884\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 48.3410 - mae: 48.3410\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 47.4753 - mae: 47.4753\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 46.6446 - mae: 46.6446\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 45.7950 - mae: 45.7950\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 44.9266 - mae: 44.9266\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 44.0763 - mae: 44.0763\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 43.2494 - mae: 43.2494\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 42.3908 - mae: 42.3908\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 41.5360 - mae: 41.5360\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 40.6728 - mae: 40.6728\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 39.8192 - mae: 39.8192\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 38.9729 - mae: 38.9729\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 38.1346 - mae: 38.1346\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 37.2484 - mae: 37.2484\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 36.4003 - mae: 36.4003\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 35.5888 - mae: 35.5888\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 34.7202 - mae: 34.7202\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 33.8997 - mae: 33.8997\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 33.0745 - mae: 33.0745\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 32.2787 - mae: 32.2787\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 31.4646 - mae: 31.4646\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.6738 - mae: 30.6738\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 29.8716 - mae: 29.8716\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.0813 - mae: 29.0813\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 28.3092 - mae: 28.3092\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 27.4820 - mae: 27.4820\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 26.7395 - mae: 26.7395\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.9308 - mae: 25.9308\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.1482 - mae: 25.1482\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.3439 - mae: 24.3439\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.5528 - mae: 23.5528\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.7548 - mae: 22.7548\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 21.9489 - mae: 21.9489\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.1221 - mae: 21.1221\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.3050 - mae: 20.3050\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 19.5278 - mae: 19.5278\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 18.7688 - mae: 18.7688\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.9457 - mae: 17.9457\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.2139 - mae: 17.2139\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.4539 - mae: 16.4539\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.7322 - mae: 15.7322\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.0101 - mae: 15.0101\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 14.2998 - mae: 14.2998\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.5697 - mae: 13.5697\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.8969 - mae: 12.8969\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.2498 - mae: 12.2498\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.5581 - mae: 11.5581\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.9163 - mae: 10.9163\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 10.3012 - mae: 10.3012\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 9.7472 - mae: 9.7472\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.3036 - mae: 9.3036\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 8.8039 - mae: 8.8039\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4302 - mae: 8.4302\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 8.1512 - mae: 8.1512\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9996 - mae: 7.9996\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.8661 - mae: 7.8661\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 7.8455 - mae: 7.8455\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.8852 - mae: 7.8852\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.9351 - mae: 7.9351\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 7.9707 - mae: 7.9707\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 7.9368 - mae: 7.9368\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.8632 - mae: 7.8632\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.7809 - mae: 7.7809\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.7005 - mae: 7.7005\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6405 - mae: 7.6405\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 7.5808 - mae: 7.5808\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.5449 - mae: 7.5449\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5160 - mae: 7.5160\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4811 - mae: 7.4811\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4610 - mae: 7.4610\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.4530 - mae: 7.4530\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 7.4353 - mae: 7.4353\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 7.4139 - mae: 7.4139\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.3878 - mae: 7.3878\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3567 - mae: 7.3567\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3315 - mae: 7.3315\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2890 - mae: 7.2890\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2580 - mae: 7.2580\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.2352 - mae: 7.2352\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2134 - mae: 7.2134\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1953 - mae: 7.1953\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.1819 - mae: 7.1819\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.1644 - mae: 7.1644\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.1491 - mae: 7.1491\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.1176 - mae: 7.1176\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0875 - mae: 7.0875\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.0548 - mae: 7.0548\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.0314 - mae: 7.0314\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f989333b5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ]
}